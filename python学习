2018.4.12
1.任何一种语言都有自己的一套语法，编译器或者解释器就是负责把符合语法的程序代码转换成cpu能够执行的机器码，然后执行。
2.python大小写敏感，最好使用4个空格缩进。
3.浮点数也就是小数，之所以称为浮点数，是因为按照科学计数法表示时，一个浮点数的小数点是可变的；整数和浮点数在计算机内部的存储方式是不同的，整数永远是精确的（除法也是），而浮点运算则可能会有四舍五入的误差。
4.如果字符串内部有很多换行，用\n写在一行里不好阅读，为了简化，Python允许用'''...'''的格式表示多行内容.
5.空值是Python里的一个特殊的值，用None表示。None不能理解为0，因为0是有意义的，而None是一个特殊的空值。
6.python变量本身的类型不固定（可把任意类型赋值给变量，同一个变量可以反复赋值），称为动态语言；与之对应是静态语言如Java（定义变量时必须指定变量类型，赋值时类型不匹配就会报错）。
7.Python中整数除法为什么也是精确的？
答：在pyton中，两种除法：a. 10/3  = 3.3333333   9/3 = 3.0 计算结果是浮点数
					b. 10//3 = 3 地板除，永远是整数
					求余 10 % 3 = 1
8.python中整数没有大小限制，浮点数也没有大小限制，超出一定范围表示为inf。
9.字符编码
		a.ASCLL编码是1个字节，而Unicode编码通常是2个字节；
			带来的问题：写的文本基本是英文的话，用Unicode编码比ascll编码需要多一倍的存储空间
		b.为节约产生“可变长编码”UTF-8编码。根据不同的数字大小编码成1-6个字节。
		c.搞清楚了ASCII、Unicode和UTF-8的关系，我们就可以总结一下现在计算机系统通用的字符编码工作方式：
			1.在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。
			2.用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件
			3.浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器,所以你看到很多网页的源码上会有类似<meta charset="UTF-8" />的信息，表示该网页正是用的UTF-8编码
		d.对于单个字符的编码，Python提供了ord（）函数获取字符的整数表示，chr()把编码转换为对应字符    ord('A')  65    chr(66)  'B'
		e.由于Python的字符串类型是str，在内存中以Unicode表示，一个字符对应若干个字节。如果要在网络上传输，或者保存到磁盘上，就需要把str变为以字节为单位的bytes。
			注意区分‘ABC’ 和 b‘ABC’,前者是str，后者是bytes;bytes的每个字符都只占用一个字节；
			以Unicode表示的str通过encode()方法可以编码为指定的bytes 如:
				>>> 'ABC'.encode('ascii')    b'ABC'
				>>>'中文'.encode('utf-8')    b'\xe4\xb8\xad\xe6\x96\x87'
			如果我们从网络或磁盘上读取了字节流，那么读到的数据就是bytes。要把bytes变为str，就需要用decode()方法：
				>>> b'ABC'.decode('ascii')
				'ABC'
				>>> b'\xe4\xb8\xad\xe6\x96\x87'.decode('utf-8')
				'中文'
		f.len()函数计算的是str的字节数，如果换成bytes,len()
		g.输出格式化的字符串：字符串里面的%是一个普通字符怎么办？这个时候就需要转义，用%%来表示一个%
			>>> 'growth rate: %d %%' % 7
				'growth rate: 7 %'
			另一种格式化字符串的方法是使用字符串的format()方法，它会用传入的参数依次替换字符串内的占位符{0}、{1}
				>>> 'Hello, {0}, 成绩提升了 {1:.1f}%'.format('小明', 17.125)
					'Hello, 小明, 成绩提升了 17.1%'
10.不可变的tuple有什么意义？因为tuple不可变，所以代码更安全。
	当你定义一个tuple时，在定义的时候，tuple的元素就必须被确定下来
	如果可能，能用tuple代替list就尽量用tuple。
	只有1个元素的tuple定义时必须加一个逗号,>>> t = (1,)
11.要特别注意，不要滥用break和continue语句。break和continue会造成代码执行逻辑分叉过多，容易出错。大多数循环并不需要用到break和continue语句，上面的两个例子，都可以通过改写循环条件或者修改循环逻辑，去掉break和continue语句。
12.请务必注意，dict内部存放的顺序和key放入的顺序是没有关系的。
dict的key必须是不可变对象;在Python中，字符串、整数等都是不可变的，因此，可以放心地作为key。而list是可变的，就不能作为key.

和list比较，dict有以下几个特点：
查找和插入的速度极快，不会随着key的增加而变慢；
需要占用大量的内存，内存浪费多。

而list相反：
查找和插入的时间随着元素的增加而增加；
占用空间小，浪费内存很少。
所以，dict是用空间来换取时间的一种方法。
13.要创建一个set，需要提供一个list作为输入集合,s = set([1, 2, 3]),在set中，没有重复的key;
对于不变对象来说，调用对象自身的任意方法，也不会改变该对象自身的内容。相反，这些方法会创建新的对象并返回，这样，就保证了不可变对象本身永远是不可变的。
14.可见，借助抽象，我们才能不关心底层的具体计算过程，而直接在更高的层次上思考问题。
写计算机程序也是一样，函数就是最基本的一种代码抽象的方式。
15.函数执行完毕也没有return语句时，自动return None。

函数可以同时返回多个值，但其实就是一个tuple。
16.新的power(x, n)函数定义没有问题，但是，旧的调用代码失败了，原因是我们增加了一个参数，导致旧的代码因为缺少一个参数而无法正常调用.
这时使用默认参数 def power(x, n=2)

默认参数可以简化函数的调用。设置默认参数时，有几点要注意：

一是必选参数在前，默认参数在后，否则Python的解释器会报错（思考一下为什么默认参数不能放在必选参数前面）；
二是如何设置默认参数。
当函数有多个参数时，把变化大的参数放前面，变化小的参数放后面。变化小的参数就可以作为默认参数。
使用默认参数有什么好处？最大的好处是能降低调用函数的难度。

定义默认参数要牢记一点：默认参数必须指向不变对象！
def add_end(L=[]):
    L.append('END')
    return L
>>> add_end()
['END']
>>> add_end()
['END', 'END']
>>> add_end()
['END', 'END', 'END']
Python函数在定义的时候，默认参数L的值就被计算出来了，即[]，因为默认参数L也是一个变量，它指向对象[]，每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。

def add_end(L=None):
    if L is None:
        L = []
    L.append('END')
    return L
为什么要设计str、None这样的不变对象呢？
	因为不变对象一旦创建，对象内部的数据就不能修改，这样就减少了由于修改数据导致的错误。此外，由于对象不变，多任务环境下同时读取对象不需要加锁，同时读一点问题都没有。我们在编写程序时，如果可以设计一个不变对象，那就尽量设计成不变对象。

17.可变参数
可变参数允许你传入0个或任意个参数，这些可变参数在函数调用时自动组装为一个tuple。
	*nums表示把nums这个list的所有元素作为可变参数传进去。这种写法相当有用，而且很常见。
	def calc(*numbers):
    sum = 0
    for n in numbers:
        sum = sum + n * n
    return sum
18.关键字参数
def person(name, age, **kw):
    print('name:', name, 'age:', age, 'other:', kw)
>>> person('Adam', 45, gender='M', job='Engineer')
name: Adam age: 45 other: {'gender': 'M', 'job': 'Engineer'}

>>> extra = {'city': 'Beijing', 'job': 'Engineer'}
>>> person('Jack', 24, city=extra['city'], job=extra['job'])
name: Jack age: 24 other: {'city': 'Beijing', 'job': 'Engineer'}

>>> extra = {'city': 'Beijing', 'job': 'Engineer'}
>>> person('Jack', 24, **extra)
name: Jack age: 24 other: {'city': 'Beijing', 'job': 'Engineer'}

关键字参数有什么用？
它可以扩展函数的功能。比如，在person函数里，我们保证能接收到name和age这两个参数，但是，如果调用者愿意提供更多的参数，我们也能收到。试想你正在做一个用户注册的功能，除了用户名和年龄是必填项外，其他都是可选项，利用关键字参数来定义这个函数就能满足注册的需求。
19.命名关键字参数
	如果要限制关键字参数的名字，就可以用命名关键字参数，例如，只接收city和job作为关键字参数。这种方式定义的函数如下：
def person(name, age, *, city, job):
    print(name, age, city, job)
>>> person('Jack', 24, city='Beijing', job='Engineer')
Jack 24 Beijing Engineer
和关键字参数**kw不同，命名关键字参数需要一个特殊分隔符*，*后面的参数被视为命名关键字参数。

如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了：
def person(name, age, *args, city, job):
    print(name, age, args, city, job)
命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：

命名关键字参数可以有缺省值，从而简化调用
def person(name, age, *, city='Beijing', job):


20.参数组合
在Python中定义函数，可以用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数都可以组合使用。但是请注意，参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。
虽然可以组合多达5种参数，但不要同时使用太多的组合，否则函数接口的可理解性很差。
对于任意函数，都可以通过类似func(*args, **kw)的形式调用它，无论它的参数是如何定义的。

21.小结
Python的函数具有非常灵活的参数形态，既可以实现简单的调用，又可以传入非常复杂的参数。

默认参数一定要用不可变对象，如果是可变对象，程序运行时会有逻辑错误！

要注意定义可变参数和关键字参数的语法：

*args是可变参数，args接收的是一个tuple；

**kw是关键字参数，kw接收的是一个dict。

以及调用函数时如何传入可变参数和关键字参数的语法：

可变参数既可以直接传入：func(1, 2, 3)，又可以先组装list或tuple，再通过*args传入：func(*(1, 2, 3))；

关键字参数既可以直接传入：func(a=1, b=2)，又可以先组装dict，再通过**kw传入：func(**{'a': 1, 'b': 2})。

使用*args和**kw是Python的习惯写法，当然也可以用其他参数名，但最好使用习惯用法。

命名的关键字参数是为了限制调用者可以传入的参数名，同时可以提供默认值。

定义命名的关键字参数在没有可变参数的情况下不要忘了写分隔符*，否则定义的将是位置参数。
22.递归函数的优点是定义简单，逻辑清晰。理论上，所有的递归函数都可以写成循环的方式，但循环的逻辑不如递归清晰。
def fact(n):
    if n==1:
        return 1
    return n * fact(n - 1)
使用递归函数需要注意防止栈溢出。在计算机中，函数调用是通过栈（stack）这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出。

解决递归调用栈溢出的方法是通过尾递归优化，事实上尾递归和循环的效果是一样的，所以，把循环看成是一种特殊的尾递归函数也是可以的。

尾递归是指，在函数返回的时候，调用自身本身，并且，return语句不能包含表达式.
def fact(n):
    return fact_iter(n, 1)

def fact_iter(num, product):
    if num == 1:
        return product
    return fact_iter(num - 1, num * product)
Python标准的解释器没有针对尾递归做优化，任何递归函数都存在栈溢出的问题。
23.当我们使用for循环时，只要作用于一个可迭代对象，for循环就可以正常运行，而我们不太关心该对象究竟是list还是其他数据类型。

那么，如何判断一个对象是可迭代对象呢？方法是通过collections模块的Iterable类型判断：
如果要对list实现类似Java那样的下标循环怎么办？Python内置的enumerate函数可以把一个list变成索引-元素对，这样就可以在for循环中同时迭代索引和元素本身：

>>> for i, value in enumerate(['A', 'B', 'C']):
...     print(i, value)
...
0 A
1 B
2 C
24.在Python中，这种一边循环一边计算的机制，称为生成器：generator。
第一种方法很简单，只要把一个列表生成式的[]改成()，就创建了一个generator：

>>> L = [x * x for x in range(10)]
>>> L
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
>>> g = (x * x for x in range(10))
>>> g
<generator object <genexpr> at 0x1022ef630>
如果要一个一个打印出来，可以通过next()函数获得generator的下一个返回值：

>>> next(g)
0
我们创建了一个generator后，基本上永远不会调用next()，而是通过for循环来迭代它，

这就是定义generator的另一种方法。如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator：
请注意区分普通函数和generator函数，普通函数调用直接返回结果：
generator函数的“调用”实际返回一个generator对象：
25.我们已经知道，可以直接作用于for循环的数据类型有以下几种：

一类是集合数据类型，如list、tuple、dict、set、str等；

一类是generator，包括生成器和带yield的generator function。

这些可以直接作用于for循环的对象统称为可迭代对象：Iterable。

可以使用isinstance()判断一个对象是否是Iterable对象：

>>> from collections import Iterable
>>> isinstance([], Iterable)
True

26.凡是可作用于for循环的对象都是Iterable类型；

凡是可作用于next()函数的对象都是Iterator类型，它们表示一个惰性计算的序列；

集合数据类型如list、dict、str等是Iterable但不是Iterator，不过可以通过iter()函数获得一个Iterator对象。

Python的for循环本质上就是通过不断调用next()函数实现的


2018.4.13

1.函数式编程
	函数式编程就是一种抽象程度很高的编程范式，纯粹的函数式编程语言编写的函数没有变量。
	函数式编程的一个特点就是，允许把函数本身作为参数传入另一个函数，还允许返回一个函数。
	高阶函数：
		1.map/reduce
		map()函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator返回。
		
		reduce把一个函数作用在一个序列[x1, x2, x3, ...]上，这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算，其效果就是：
		reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)
>>> def f(x):
...    return x * x
...
>>> r = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])
>>> list(r)
[1, 4, 9, 16, 25, 36, 49, 64, 81]

>>> from functools import reduce
>>> def fn(x, y):
...     return x * 10 + y
...
>>> reduce(fn, [1, 3, 5, 7, 9])
13579
		2.Python内建的filter()函数用于过滤序列。

		和map()类似，filter()也接收一个函数和一个序列。和map()不同的是，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。
			def is_odd(n):
    			return n % 2 == 1

			list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))
			
	# 结果: [1, 5, 9, 15]
找回数：
def is_palindrome(n):
    return str(n) == str(n)[::-1]

output = filter(is_palindrome, range(1, 1000))
print('1~1000:', list(output))
if list(filter(is_palindrome, range(1, 200))) == [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 22, 33, 44, 55, 66, 77, 88, 99, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191]:
    print('测试成功!')
else:
    print('测试失败!')	


s='123'
s[::-1] = '321'

sorted()函数
sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower)
['about', 'bob', 'Credit', 'Zoo']
>>> sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower, reverse=True)
['Zoo', 'Credit', 'bob', 'about']



2018.4.16
返回函数   闭包
	不需要立即求和，而是在后面的代码中，根据需要在计算
	def lazy_sum(*args):
    def sum():
        ax = 0
        for n in args:
            ax = ax + n
        return ax
    return sum
    在函数lazy_sum中又定义了函数sum，并且，内部函数sum可以引用外部函数lazy_sum的函数和局部变量，当lazy_sum返回函数sum时，相关参数和变量都保存在返回的函数中，
    这种程序结构称为“闭包（closure）”
    会发生的问题：
    def count():
    fs = []
    for i in range(1, 4):
        def f():
             return i*i
        fs.append(f)
    return fs

	f1, f2, f3 = count()

	>>>f1() 9
	>>>f2() 9
	>>>f3() 9
	都是9，原因在于返回的函数引用变量i,但它并非立刻执行，等到3个函数都返回时，他们所引用的变量i已经变成了3，因此最终结果为9.
    返回闭包时，牢记一点：返回函数不要引用任何循环变量，或者后续会发生变化的变量

    如果一定要引用循环变量？再创建一个函数，用该函数的参数绑定循环变量当前的值。
    def count():
    def f(j):
        def g():
            return j*j
        return g
    fs = []
    for i in range(1, 4):
        fs.append(f(i)) # f(i)立刻被执行，因此i的当前值被传入f()
    return fs

    >>> f1, f2, f3 = count()
	>>> f1()
	1
	>>> f2()
	4
	>>> f3()
	9

	利用闭包返回一个计数器函数，每次调用他返回递增整数：
	def createCounter():
    s = [0]
    def counter():
        s[0] += 1
        return s[0]
    return counter

	做些笔记：
	1.内部函数一般无法修改外部函数的参数
	2.想要修改需要声明 nonlocal
	3.内部函数可以修改外部list中的元素

2.匿名函数
	匿名函数lambda x: x * x 实际上就是
	def f(x):
		return x * x
	冒号前x表示函数参数；
	限制：只能有一个表达式，不用写return，返回值就是该表达式的结果
	好处：函数没名字，不用担心函数名冲突；匿名函数也是一个函数对象。

3.装饰器
	要增加函数的功能，又不想修改函数的定义，这种在代码运行期间动态增加功能的方式，称为“装饰器”（Decorator）

一个完整的decorator的写法如下：
import functools

def log(func):
    @functools.wraps(func)
    def wrapper(*args, **kw):
        print('call %s():' % func.__name__)
        return func(*args, **kw)
    return wrapper


针对带参数的decorator：
import functools

def log(text):
    def decorator(func):
        @functools.wraps(func)#不加这一行的话调用now.__name__ 会显示wrapper,而不会显示now
        def wrapper(*args, **kw):
            print('%s %s():' % (text, func.__name__))
            return func(*args, **kw)
        return wrapper
    return decorator

@log('execute')
def now():
    print('2015-3-25')

>>> now()
execute now():
2015-3-25

4.偏函数
	通过设定函数的默认值，可以降低调用函数的难度，偏函数也可以做到这一点；
	functools.partial 就是帮助我们创建一个偏函数的。作用就是把一个函数的某些参数给固定住（也就是设置默认值，）
	返回一个新的函数，调用这个新函数会更简单。
	创建偏函数时，实际上可以接收函数对象、*args和**kw这3个参数，
	当传入int2 = functools.partial(int, base=2)
	int2('10010')
	kw = { 'base': 2 }
	int('10010', **kw)
	当传入max2 = functools.partial(max, 10)实际上会把10作为*args的一部分自动加到左边
	也就是max2(5, 6, 7)相当于args = (10, 5, 6, 7)
	max(*args) 结果为10

	当函数的参数个数太多，需要简化时，使用functools.partial可以创建一个新的函数，这个新函数可以固定住原函数的部分参数，从而在调用时更简单。
	
2018.4.17
1.模块：
	提高代码的课维护性；编写代码不必从零开始。
	可以避免函数名和变量名冲突。但也要避免与内置函数名字冲突。（如系统自带sys模块，自己命名的模块就不可命名为sys.py，否则无法导入系统自带的sys模块）
	为避免模块名冲突，Python引入按目录来组织模块的方法，称为”包“package。
	注意，每一个包目录下都会有一个__init__.py的文件，这个文件必须存在，否则Python就把这个目录当成普通目录，而不是一个包。__init__.py本身是一个模块，他的模块名就是包名

	创建自己的模块时，要注意：
		模块名要遵循Python变量命名规范，不要使用中文、特殊字符；
		模块名不要和系统模块名冲突，最好先查看系统是否已存在该模块，检查方法是在Python交互环境执行import abc，若成功则说明系统存在此模块。
	作用域：
		在Python中是通过_前缀来实现的private的
		类似__xxx__这样的变量是特殊变量，可以被直接引用，但是有特殊用途。
	安装第三方模块：
		pip install Pillow
		第三方库都会在Python官方的pypi.python.org网站注册
		默认情况下，Python解释器会搜索当前目录、所有已安装的内置模块，和第三方模块，搜索路径存放在sys模块的path变量中：
		import sys  sys.path
		要添加自己的搜索目录，两种方法：
			直接修改sys.path
					import sys
					sys.path.append('/')
					在运行时修改，运行结束后失效
			设置环境变量PYTHONPATH，该环境变量的内容会被自动添加到模块搜索路径中。
2.面向对象编程OOP 封装 继承 多态
	面向过程的程序吧计算机程序视为一系列命令集合，即一组函数的顺序执行，为了简化程序设计，面向过程把函数继续切分为子函数，即把大块函数切割成小块函数来降低系统的复杂度。
	面向对象程序设计吧计算机程序视为一组对象的集合，而每个对象可以接收其他对象发过来的消息，并处理这些消息，计算机程序执行的就是一系列消息在各个对象之间的传递。
	给对象发消息就是调用对象对应的关联函数，，我们称之为对象的方法。
	面向对象的设计思想是抽象出class，根据class创建instance。
	类和实例：
		类可以起到模板的作用，可以在创建实例的时候，把一些我们认为必须绑定的属性强制填写进去，通过定义一个特殊的__init__方法。（两个下划线）
		和普通函数相比，在类中定义的函数只有一点不同，就是第一个参数永远是实例变量self，但调用时，不用传递该参数。除此外，与普通函数美什么区别。仍可以用默认参数，可变参数，关键字参数，和命名关键字参数
		封装：
			好处：数据和逻辑被封装，调用容易，不需要知道内部实现的细节；可以给类增加新的方法；
		和静态语言不同，Python允许对实例变量绑定任何数据，也就是说，对于两个实例变量，虽然他们都是同一个类的不同实例，但拥有的变量名称都可能不同。
	访问限制： 可以使代码更加健壮。
		要让内部属性不被外部访问，可以把属性名称前加两个下划线__，在Python中，实例的变量名如果以__开头，就变成了一个私有变量，只有内部可以访问，外部不可以访问。Python解释器对外把__name变量改成_Student__name或其他变量名（不同Python解释器可能改的不同）.
		在方法中，可以对参数做检查，避免传入无效的参数，故有setter函数
		在Python中，变量名类似__xxx__，双下划线开头结尾，是特殊变量，可以直接访问，不是private变量
		以一个下划线开头的变量，外部可以访问，但约定，最好当成私有变量。
	继承和多态：
		继承：最大的好处就是获得了父类的全部功能；第二个好处就是需要我们队代码做一点改进。继承的另一个好处，多态
		多态：调用方只管调用，不管细节，而当我们新增一个Animal的子类时，只要确保run()方法编写正确，不管原来的代码是如何调用的，这就是
		著名的”开闭原则“：
			对扩展开放:允许新增Animal子类
			对修改封闭：不需要修改依赖Animal类型的run_twice()等函数。
		def run_twice(animal):
    		animal.run()
    		animal.run()

    	>>> run_twice(Animal())
			Animal is running...
			Animal is running...
		>>> run_twice(Cat())
			Cat is running...
			Cat is running...
		静态语言vs动态语言：
			静态语言如java，如需要传入Animal类型，则传入对象必须是这类型或者他的子类，否则无法调用run()方法。
			动态语言，不一定要传入Animal类型或其子类，只要保证传入对象有一个run()方法就可以了。这就是动态语言的“鸭子类型”，不要求严格的继承体系。
			class Timer(object):
    			def run(self):
       				print('Start...')
    获取对象信息：
    	判断对象类型：使用type()函数
    		>>> type('abc')==type('123')
				True
    	判断一个对象是否是函数怎么办？可以使用types模块中定义的常量
    		>>> import types
			>>> def fn():
			...     pass
			...
			>>> type(fn)==types.FunctionType
			True
		对于class的继承关系来说，使用type()就很不方便。我们要判断class的类型，可以使用isinstance()函数
			isinstance()判断的是一个对象是否是该类型本身，或者位于该类型的父继承链上。
			能用type()判断的基本类型也可以用isinstance()判断：
				>>> isinstance('a', str)
					True
			可以判断一个变量是否是某些类型中的一种，比如下面的代码就可以判断是否是list或者tuple：
				>>> isinstance([1, 2, 3], (list, tuple))
					True
			总是优先使用isinstance()判断类型，可以将指定类型及其子类“一网打尽”
		使用dir():
			如果要获得一个对象的所有属性和方法，可以使用dir()函数，它返回一个包含字符串的list，比如，获得一个str对象的所有属性和方法
			在len()函数内部，它自动去调用该对象的__len__()方法，所以，下面的代码是等价的：
				>>> len('ABC')
					3
				>>> 'ABC'.__len__()
					3
		仅仅把属性和方法列出来是不够的，配合getattr()、setattr()以及hasattr()，我们可以直接操作一个对象的状态：
			正确的用法的例子如下：

			def readImage(fp):
    			if hasattr(fp, 'read'):
       				return readData(fp)
  				return None
			假设我们希望从文件流fp中读取图像，我们首先要判断该fp对象是否存在read方法，如果存在，则该对象是一个流，如果不存在，则无法读取。hasattr()就派上了用场。
			请注意，在Python这类动态语言中，根据鸭子类型，有read()方法，不代表该fp对象就是一个文件流，它也可能是网络流，也可能是内存中的一个字节流，但只要read()方法返回的是有效的图像数据，就不影响读取图像的功能。
	实例属性和类属性：
		给实例绑定属性的方法是通过实例变量，或者通过self变量；
		如果是类本身需要绑定一个属性，可以直接在class中定义属性，这种属性是类所有；但类的所有 实例都可以访问到。
		在编写程序的时候，千万不要对实例属性和类属性使用相同的名字，因为相同名称的实例属性将屏蔽掉类属性，但是当你删除实例属性后，再使用相同的名称，访问到的将是类属性。
		>>> class Student(object):
		...     name = 'Student'
		...
		>>> s = Student() # 创建实例s
		>>> print(s.name) # 打印name属性，因为实例并没有name属性，所以会继续查找class的name属性
		Student
		>>> print(Student.name) # 打印类的name属性
		Student
		>>> s.name = 'Michael' # 给实例绑定name属性
		>>> print(s.name) # 由于实例属性优先级比类属性高，因此，它会屏蔽掉类的name属性
		Michael
		>>> print(Student.name) # 但是类属性并未消失，用Student.name仍然可以访问
		Student
		>>> del s.name # 如果删除实例的name属性
		>>> print(s.name) # 再次调用s.name，由于实例的name属性没有找到，类的name属性就显示出来了
		Student
		实例属性属于各个实例所有，互不干扰；

		类属性属于类所有，所有实例共享一个属性；

		不要对实例属性和类属性使用相同的名字，否则将产生难以发现的错误。
		例子：每创建一个实例，count加1
		class Student(object):
			count = 0#每次实例化对象的时候，只需init来为其绑定属性，不会执行类属性部分，即从类属性之后的部分开始运行的，故每次创建实例不会初始化为0
			def __init__(self,name):
				self.__name = name
				Student.count = Student.count + 1#1、init方法是绑定实例的属性用的，不能调用类属性count，故要加Student。
3.面向对象高级编程
	使用__slots__:
		当我们定义了一个class，创建了一个class的实例后，可以给该实例绑定任何属性和方法，这就是动态语言的灵活性。
		但是，给一个实例绑定的方法，对另一个实例是不起作用的，为了给所有实例都绑定方法，可以给class绑定方法。
		>>> def set_score(self, score):
		...     self.score = score
		...
		>>> Student.set_score = set_score
		给class绑定方法后，所有实例均可调用
		>>> s.set_score(100)
		>>> s.score
			100
		>>> s2.set_score(99)
		>>> s2.score
			99
		通常情况下，上面的set_score方法可以直接定义在class中，但动态绑定允许我们在程序运行的过程中动态给class加上功能，这在静态语言中很难实现。
		为了达到限制的目的，Python允许在定义class的时候，定义一个特殊的__slots__变量，来限制该class实例能添加的属性；
		class Student(object):
    		__slots__ = ('name', 'age') # 用tuple定义允许绑定的属性名称
    	>>> s = Student() # 创建新的实例
		>>> s.name = 'Michael' # 绑定属性'name'
		>>> s.age = 25 # 绑定属性'age'
		>>> s.score = 99 # 绑定属性'score'
			Traceback (most recent call last):
 			File "<stdin>", line 1, in <module>
			AttributeError: 'Student' object has no attribute 'score'
		使用__slots__变量时，定义的属性仅对当前类实例起作用，对继承的子类是不起作用的。
		除非在子类中也定义__slots__，这样，子类实例允许定义的属性就是自身的__slots__加上父类的__slots__
	使用@property:
		负责把一个方法编程属性调用的。广泛应用在类的定义中，可以让调用者写出简短的代码，同时保证对参数进行必要的检查，这样，程序运行时就减少了出错的可能性。
		既能检查参数又能用类似属性这样简单的方式来访问类的变量。
		
		把一个getter方法变成属性，只需要加上@property就可以了，此时，@property本身又创建了另一个装饰器@score.setter，负责把一个setter方法变成属性赋值，于是，我们就拥有一个可控的属性操作

		还可以定义只读属性，只定义getter方法，不定义setter方法就是一个只读属性：
		class Student(object):

   			@property
    		def birth(self):
        		return self._birth

    		@birth.setter
    		def birth(self, value):
        		self._birth = value

    		@property
    		def age(self):
        		return 2015 - self._birth
    多重继承：
    	通过多重继承，一个子类就可以获得多个父类的所有功能。Mixln是一种常见的设计（Java只允许单继承，不能用Mixln的设计）
    	class Dog(Mammal, Runnable):
    		pass
    定制类：
    	__str__   __repr__:
    		怎么才能打印得好看呢？只需要定义好__str__()方法，返回一个好看的字符串就可以了：

			>>> class Student(object):
			...     def __init__(self, name):
			...         self.name = name
			...     def __str__(self):
			...         return 'Student object (name: %s)' % self.name
			...
			>>> print(Student('Michael'))
			Student object (name: Michael)
		__iter__:
			如果一个类想被用于for。。。in 循环，类似list或tuple那样，就必须实现一个__iter__()方法，该方法返回一个迭代对象，然后，Python的for循环就会不断调用该迭代对象的__next__()方法拿到循环的下一个值，直到遇到StopIteration错误。
		__getitem__:
			表现得像list那样按照下标取出元素，实现__getitem__()方法。
		__getattr__:
			调用类的方法或属性时，不存在时报错，实现这__getattr__()方法后，动态返回一个属性。
			class Student(object):

    			def __init__(self):
       				self.name = 'Michael'

    			def __getattr__(self, attr):
        			if attr=='score':
            			return 99
            >>> s = Student()
			>>> s.name
			'Michael'
			>>> s.score
			99
			可以把一个类的所有属性和方法调用全部动态化处理，这种完全动态调用的特性有什么实际作用呢？作用就是可以针对完全动态的情况作调用。REST API
		__call__:
			任何类，只需要定义一个__call__()方法，就可以直接对实例进行调用
				class Student(object):
    				def __init__(self, name):
        				self.name = name

    				def __call__(self):
        				print('My name is %s.' % self.name)
        		>>> s = Student('Michael')
				>>> s() # self参数不要传入
					My name is Michael.
			，怎么判断一个变量是对象还是函数呢？其实，更多的时候，我们需要判断一个对象是否能被调用，能被调用的对象就是一个Callable对象，比如函数和我们上面定义的带有__call__()的类实例：
			>>> callable(Student())
				True
				通过callable()函数，我们就可以判断一个对象是否是“可调用”对象
	枚举类：
		为这样的枚举类型定义一个class类型，然后，每个常量都是class的一个唯一实例。Python提供了Enum类来实现这个功能
		from enum import Enum

		Month = Enum('Month', ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))
		value属性则是自动赋给成员的int常量，默认从1开始计数。

如果需要更精确地控制枚举类型，可以从Enum派生出自定义类：

from enum import Enum, unique

@unique
class Weekday(Enum):
    Sun = 0 # Sun的value被设定为0
    Mon = 1
    Tue = 2
    Wed = 3
    Thu = 4
    Fri = 5
    Sat = 6
@unique装饰器可以帮助我们检查保证没有重复值。
		既可以用成员名称引用枚举常量，又可以直接根据value的值获得枚举常量
		Enum可以把一组相关常量定义在一个class中，且class不可变，而且成员可以直接比较。


	元类：
		type()
		动态语言和静态语言最大不同就是函数和类的定义，不是编译时定义的，而是运行时动态创建的。
		要创建一个class对象，type()函数依次传入3个参数：
			1.class的名称；
			2.继承的父类集合，注意Python支持多重继承，如果只有一个父类，别忘了tuple的单元素写法；
			3.class的方法名称与函数绑定，这里我们把函数fn绑定到方法名hello上。
			通过type()函数创建的类和直接写class是完全一样的，因为Python解释器遇到class定义时，仅仅是扫描一下class定义的语法，然后调用type()函数创建出class。

		metaclass:元类
			当我们定义了类以后，就可以根据这个类创建出实例，所以：先定义类，然后创建实例。
			但是如果我们想创建出类呢？那就必须根据metaclass创建出类，所以：先定义metaclass，然后创建类。
			总会遇到需要通过metaclass修改类定义的。ORM就是一个典型的例子
			ORM全称“Object Relational Mapping”，即对象-关系映射，就是把关系数据库的一行映射为一个对象，也就是一个类对应一个表，这样，写代码更简单，不用直接操作SQL语句。

			metaclass是Python中非常具有魔术性的对象，它可以改变类创建时的行为。

2018.4.18
	错误、调试和测试
		错误处理：
				Python内置了try。。。except...finally...错误处理机制
				如果没有错误发生，可以在except语句块后面加一个else，当没有错误发生时，会自动执行else语句
				Python的错误其实也是class，所有的错误类型都继承自BaseException，所以在使用except时需要注意的是，它不但捕获该类型的错误，还把其子类也“一网打尽”。
				使用try...except捕获错误还有一个巨大的好处，就是可以跨越多层调用
				解读错误信息是定位错误的关键
		 		出错的时候，一定要分析错误的调用栈信息，才能定位错误的位置。
		 	记录错误：
		 		Python内置的logging模块可以非常容易的记录错误信息；
		 	# err_logging.py

					import logging

					def foo(s):
					    return 10 / int(s)

					def bar(s):
					    return foo(s) * 2

					def main():
					    try:
					        bar('0')
					    except Exception as e:
					        logging.exception(e)

					main()
						print('END')
				同样是出错，但程序打印完错误信息后会继续执行，并正常退出
				通过配置，logging可以把错误记录到日志文件，方便事后排查
			抛出错误：raise
				因为错误是class，捕获一个错误就是捕获到该class的一个实例。
				要抛出错误，首先根据需要，可以定义一个错误的class，选择好继承关系，然后，用raise语句抛出一个错误的实例
				# err_raise.py
				class FooError(ValueError):
				    pass

				def foo(s):
				    n = int(s)
				    if n==0:
				        raise FooError('invalid value: %s' % s)
				    return 10 / n

				foo('0')
				$ python3 err_raise.py 
				Traceback (most recent call last):
				  File "err_throw.py", line 11, in <module>
				    foo('0')
				  File "err_throw.py", line 8, in foo
				    raise FooError('invalid value: %s' % s)
				__main__.FooError: invalid value: 0
							我们来看另一种错误处理的方式：
							# err_reraise.py

					def foo(s):
					    n = int(s)
					    if n==0:
					        raise ValueError('invalid value: %s' % s)
					    return 10 / n

					def bar():
					    try:
					        foo('0')
					    except ValueError as e:
					        print('ValueError!')
					        raise#重点

							bar()
						打印ValueError后，又把错误通过raise语句抛出去了，raise语句如果不带参数，就会把当前错误原样抛出。在except中raise一个error，还可以把一种类型的错误转化为另一种类型
						Python内置的try...except...finally用来处理错误十分方便。出错时，会分析错误信息并定位错误发生的代码位置才是最关键的。

						程序也可以主动抛出错误，让调用者来处理相应的错误。但是，应该在文档中写清楚可能会抛出哪些错误，以及错误产生的原因。
		调试：
			print():
				简单直接粗暴有效；坏处是将来还得删除它；
			断言：
				凡是print()来辅助查看的地方，都可以用断言assert来替代
							def foo(s):
							    n = int(s)
							    assert n != 0, 'n is zero!'
							    return 10 / n

							def main():
								    foo('0')
					assert的意思是，表达式n != 0应该是True，否则，根据程序运行的逻辑，后面的代码肯定会出错。

					如果断言失败，assert语句本身就会抛出AssertionError：

					$ python err.py
					Traceback (most recent call last):
					  ...
					AssertionError: n is zero!
				若到处充斥着assert和print（）相比也好不到那里去。不过启动Python解释器可以用-o参数来关闭assert。
					$ python -O err.py
					Traceback (most recent call last):
					  ...
					ZeroDivisionError: division by zero
					关闭后，你可以把所有的assert语句当成pass来看。
			logging：
				把print()替换为logging是第3种方式，和assert比，logging不会抛出错误，而且可以输出到文件
				import logging

				s = '0'
				n = int(s)
				logging.info('n = %d' % n)
				print(10 / n)
				logging.info()就可以输出一段文本。
				运行，发现除了ZeroDivisionError，没有任何信息。怎么回事？

				别急，在import logging之后添加一行配置再试试：

				import logging
				logging.basicConfig(level=logging.INFO)
				看到输出了：

				$ python err.py
				INFO:root:n = 0
				Traceback (most recent call last):
				  File "err.py", line 8, in <module>
				    print(10 / n)
				ZeroDivisionError: division by zero
				这就是logging的好处，它允许你指定记录信息的级别，有debug，info，warning，error等几个级别，当我们指定level=INFO时，logging.debug就不起作用了。同理，指定level=WARNING后，debug和info就不起作用了。这样一来，你可以放心地输出不同级别的信息，也不用删除，最后统一控制输出哪个级别的信息。

				logging的另一个好处是通过简单的配置，一条语句可以同时输出到不同的地方，比如console和文件。
			pdb:
				第4种方式是启动Python的调试器pdb，让程序以单步方式运行，可以随时查看运行状态
				$ python -m pdb err.py
				> /Users/michael/Github/learn-python3/samples/debug/err.py(2)<module>()
				-> s = '0'
				以参数-m pdb启动后，pdb定位到下一步要执行的代码-> s = '0'。输入命令l来查看代码：
				输入命令n可以单步执行代码：
				任何时候都可以输入命令p 变量名来查看变量：
				输入命令q结束调试，退出程序：
				理论上万能，但太麻烦，有一千行代码得敲很多次	
			pdb.set_trace():
				这个方法也是用pdb，但是不需要单步执行，我们只需要import pdb，然后，在可能出错的地方放一个pdb.set_trace()，就可以设置一个断点：
				# err.py
				import pdb

				s = '0'
				n = int(s)
				pdb.set_trace() # 运行到这里会自动暂停
				print(10 / n)
				运行代码，程序会自动在pdb.set_trace()暂停并进入pdb调试环境，可以用命令p查看变量，或者用命令c继续运行：
				这个方式比直接启动pdb单步调试效率要高很多，但也高不到哪去
			IDE
				如果要比较爽地设置断点、单步执行，就需要一个支持调试功能的IDE。
			写程序最痛苦的事情莫过于调试，程序往往会以你意想不到的流程来运行，你期待执行的语句其实根本没有执行，这时候，就需要调试了。

			虽然用IDE调试起来比较方便，但是最后你会发现，logging才是终极武器。
		单元测试：
			测试驱动开发”（TDD：Test-Driven Development）
			单元测试是用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作。
			以测试为驱动的开发模式最大的好处就是确保一个程序模块的行为符合我们设计的测试用例
			为了编写单元测试，我们需要引入Python自带的unittest模块
			编写单元测试时，我们需要编写一个测试类，从unittest.TestCase继承。

			以test开头的方法就是测试方法，不以test开头的方法不被认为是测试方法，测试的时候不会被执行。
			运行单元测试：
				最简单的运行方式是在mydict_test.py的最后加上两行代码：

					if __name__ == '__main__':
					    unittest.main()
				另一种方法是在命令行通过参数-m unittest直接运行单元测试：

					$ python -m unittest mydict_test
					.....
				可以在单元测试中编写两个特殊的setUp()和tearDown()方法。这两个方法会分别在每调用一个测试方法的前后分别被执行。
		文档测试：
			当模块正常导入时，doctest不会被执行。只有在命令行直接运行时，才执行doctest
			doctest非常有用，不但可以用来测试，还可以直接作为示例代码。通过某些文档生成工具，就可以自动把包含doctest的注释提取出来。用户看文档的时候，同时也看到了doctest。
			当模块正常导入时，doctest不会被执行。只有在命令行直接运行时，才执行doctest。所以，不必担心doctest会在非测试环境下执行。
			让我们用doctest来测试上次编写的Dict类：

			# mydict2.py
			class Dict(dict):
			    '''
			    Simple dict but also support access as x.y style.

			    >>> d1 = Dict()
			    >>> d1['x'] = 100
			    >>> d1.x
			    100
			    >>> d1.y = 200
			    >>> d1['y']
			    200
			    >>> d2 = Dict(a=1, b=2, c='3')
			    >>> d2.c
			    '3'
			    >>> d2['empty']
			    Traceback (most recent call last):
			        ...
			    KeyError: 'empty'
			    >>> d2.empty
			    Traceback (most recent call last):
			        ...
			    AttributeError: 'Dict' object has no attribute 'empty'
			    '''
			    def __init__(self, **kw):
			        super(Dict, self).__init__(**kw)

			    def __getattr__(self, key):
			        try:
			            return self[key]
			        except KeyError:
			            raise AttributeError(r"'Dict' object has no attribute '%s'" % key)

			    def __setattr__(self, key, value):
			        self[key] = value

			if __name__=='__main__':
			    import doctest
			    doctest.testmod()
	IO编程：
		涉及到数据交换的地方，通常是磁盘，网络等，就需要io接口
		通常，程序完成io操作会有input和output两个数据流。
		Input Stream就是数据从外面（磁盘、网络）流进内存，Output Stream就是数据从内存流到外面去。
		由于CPU和内存的速度远远高于外设的速度，所以，在IO编程中，就存在速度严重不匹配的问题。
			有两种方法：同步IO，异步IO。
				第一种是CPU等着，也就是程序暂停执行后续代码，等100M的数据在10秒后写入磁盘，再接着往下执行，这种模式称为同步IO；
				另一种方法是CPU不等待，只是告诉磁盘，“您老慢慢写，不着急，我接着干别的事去了”，于是，后续代码可以立刻接着执行，这种模式称为异步IO。
			使用异步IO来编写程序性能会远远高于同步IO，但是异步IO的缺点是编程模型复杂。
		文件读写：
			读：
				>>> f = open('/Users/michael/test.txt', 'r')#默认读取文本文件，并且是utf-8编码的文本文件
				>>> f.read()
				'Hello, world!'
				>>>f.close()
				由于文件读写时都有可能产生IOError，一旦出错，后面的f.close()就不会调用。所以，为了保证无论是否出错都能正确地关闭文件，我们可以使用try ... finally来实现
				Python引入了with语句来自动帮我们调用close()方法：
				with open('/path/to/file', 'r') as f:
				    print(f.read())
				调用read()会一次性读取文件的全部内容;如果文件很小，read()一次性读取最方便；如果不能确定文件大小，反复调用read(size)比较保险
				调用readline()可以每次读取一行内容
				调用readlines()一次读取所有内容并按行返回list;如果是配置文件，调用readlines()最方便
				file-like Object
					像open()函数返回的这种有个read()方法的对象，在Python中统称为file-like Object。除了file外，还可以是内存的字节流，网络流，自定义流等等。file-like Object不要求从特定类继承，只要写个read()方法就行。

					StringIO就是在内存中创建的file-like Object，常用作临时缓冲。
				要读取二进制文件，比如图片、视频等等，用'rb'模式打开文件即可：
					>>> f = open('/Users/michael/test.jpg', 'rb')
				要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取GBK编码的文件：
					>>> f = open('/Users/michael/gbk.txt', 'r', encoding='gbk')
					遇到有些编码不规范的文件，你可能会遇到UnicodeDecodeError，因为在文本文件中可能夹杂了一些非法编码的字符。遇到这种情况，open()函数还接收一个errors参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略：
					>>> f = open('/Users/michael/gbk.txt', 'r', encoding='gbk', errors='ignore')
			写文件：
				写文件和读文件是一样的，唯一区别是调用open()函数时，传入标识符'w'或者'wb'表示写文本文件或写二进制文件：
					>>> f = open('/Users/michael/test.txt', 'w')
					>>> f.write('Hello, world!')
					>>> f.close()
					当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。只有调用close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。忘记调用close()的后果是数据可能只写了一部分到磁盘，剩下的丢失了。所以，还是用with语句来得保险：
					with open('/Users/michael/test.txt', 'w') as f:
	    				f.write('Hello, world!')
	    			要写入特定编码的文本文件，请给open()函数传入encoding参数，将字符串自动转换成指定编码。
	    			以'w'模式写入文件时，如果文件已存在，会直接覆盖（相当于删掉后新写入一个文件）。如果我们希望追加到文件末尾怎么办？可以传入'a'以追加（append）模式写入。
	    		在Python中，文件读写是通过open()函数打开的文件对象完成的。使用with语句操作文件IO是个好习惯。
	    StingIO和BytesIO:
	    	StringIO顾名思义就是在内存中读写str。

				要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可：

				>>> from io import StringIO
				>>> f = StringIO()
				>>> f.write('hello')
				5
				>>> f.write(' ')
				1
				>>> f.write('world!')
				6
				>>> print(f.getvalue())
				hello world!
				getvalue()方法用于获得写入后的str。
			要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取：

				>>> from io import StringIO
				>>> f = StringIO('Hello!\nHi!\nGoodbye!')
				>>> while True:
				...     s = f.readline()
				...     if s == '':
				...         break
				...     print(s.strip())
				...
				Hello!
				Hi!
				Goodbye!
			BytesIO
				StringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO。

				BytesIO实现了在内存中读写bytes，我们创建一个BytesIO，然后写入一些bytes：

				>>> from io import BytesIO
				>>> f = BytesIO()
				>>> f.write('中文'.encode('utf-8'))
				6
				>>> print(f.getvalue())
				b'\xe4\xb8\xad\xe6\x96\x87'
				请注意，写入的不是str，而是经过UTF-8编码的bytes。

				和StringIO类似，可以用一个bytes初始化BytesIO，然后，像读文件一样读取：
			StringIO和BytesIO是在内存中操作str和bytes的方法，使得和读写文件具有一致的接口

				>>> from io import BytesIO
				>>> f = BytesIO(b'\xe4\xb8\xad\xe6\x96\x87')
				>>> f.read()
					b'\xe4\xb8\xad\xe6\x96\x87'
		操作文件和目录：
			>>> import os
				>>> os.name # 操作系统类型
				'posix'
			要获取详细的系统信息，可以调用uname()函数：
				>>> os.uname()
			在操作系统中定义的环境变量，全部保存在os.environ这个变量中，可以直接查看：
				>>> os.environ
			要获取某个环境变量的值，可以调用os.environ.get('key')：
			查看、创建和删除目录可以这么调用：

				# 查看当前目录的绝对路径:
				>>> os.path.abspath('.')
				'/Users/michael'
				# 在某个目录下创建一个新目录，首先把新目录的完整路径表示出来:
				>>> os.path.join('/Users/michael', 'testdir')
				'/Users/michael/testdir'
				# 然后创建一个目录:
				>>> os.mkdir('/Users/michael/testdir')
				# 删掉一个目录:
				>>> os.rmdir('/Users/michael/testdir')
			把两个路径合成一个时，不要直接拼字符串，而要通过os.path.join()函数，这样可以正确处理不同操作系统的路径分隔符
			同样的道理，要拆分路径时，也不要直接去拆字符串，而要通过os.path.split()函数，这样可以把一个路径拆分为两部分，后一部分总是最后级别的目录或文件名：
			>>> os.path.split('/Users/michael/testdir/file.txt')
				('/Users/michael/testdir', 'file.txt')
			os.path.splitext()可以直接让你得到文件扩展名，很多时候非常方便
			>>> os.path.splitext('/path/to/file.txt')
				('/path/to/file', '.txt')
			这些合并、拆分路径的函数并不要求目录和文件要真实存在，它们只对字符串进行操作。
			假定当前目录下有一个test.txt文件：

			# 对文件重命名:
			>>> os.rename('test.txt', 'test.py')
			# 删掉文件:
			>>> os.remove('test.py')
			但是复制文件的函数居然在os模块中不存在！原因是复制文件并非由操作系统提供的系统调用。幸运的是shutil模块提供了copyfile()的函数，你还可以在shutil模块中找到很多实用函数，它们可以看做是os模块的补充。
				要列出所有的.py文件，也只需一行代码：

			>>> [x for x in os.listdir('.') if os.path.isfile(x) and os.path.splitext(x)[1]=='.py']
			['apis.py', 'config.py', 'models.py', 'pymonitor.py', 'test_db.py', 'urls.py', 'wsgiapp.py']
		Python的os模块封装了操作系统的目录和文件操作，要注意这些函数有的在os模块中，有的在os.path模块中。

		序列化：
			在程序运行的过程中，所有的变量都是在内存中，可以随时修改变量，但是一旦程序结束，变量所占用的内存就被操作系统全部回收。
			我们把变量从内存中变成可存储或传输的过程称之为序列化，在Python中叫pickling，在其他语言中也被称之为serialization，marshalling，flattening等等，都是一个意思。
			把变量内容从序列化的对象重新读到内存里称之为反序列化，即unpickling
			Python提供了pickle模块来实现序列化。
		JSON：
			如果我们要在不同的编程语言之间传递对象，就必须把对象序列化为标准格式，比如XML，但更好的方法是序列化为JSON，因为JSON表示出来就是一个字符串，可以被所有语言读取，也可以方便地存储到磁盘或者通过网络传输。JSON不仅是标准格式，并且比XML更快，而且可以直接在Web页面中读取，非常方便。
			Python内置的json模块提供了非常完善的Python对象到JSON格式的转换。我们先看看如何把Python对象变成一个JSON：
				>>> import json
				>>> d = dict(name='Bob', age=20, score=88)
				>>> json.dumps(d)
				'{"age": 20, "score": 88, "name": "Bob"}'
			dumps()方法返回一个str，内容就是标准的JSON。
			要把JSON反序列化为Python对象，用loads()或者对应的load()方法，前者把JSON的字符串反序列化，后者从file-like Object中读取字符串并反序列化：

			>>> json_str = '{"age": 20, "score": 88, "name": "Bob"}'
			>>> json.loads(json_str)
			{'age': 20, 'score': 88, 'name': 'Bob'}
			由于JSON标准规定JSON编码是UTF-8，所以我们总是能正确地在Python的str与JSON的字符串之间转换。
		JSON进阶：
			把class实例对象s序列化为json：
				print(json.dumps(s,default=lambda obj: obj.__dict__))
			如果我们要把JSON反序列化为一个Student对象实例，loads()方法首先转换出一个dict对象，然后，我们传入的object_hook函数负责把dict转换为Student实例：
				def dict2student(d):
				    return Student(d['name'], d['age'], d['score'])
				运行结果如下：

				>>> json_str = '{"age": 20, "score": 88, "name": "Bob"}'
				>>> print(json.loads(json_str, object_hook=dict2student))
				<__main__.Student object at 0x10cd3c190>
				打印出的是反序列化的Student实例对象
		Python语言特定的序列化模块是pickle，但如果要把序列化搞得更通用、更符合Web标准，就可以使用json模块。
		json模块的dumps()和loads()函数是定义得非常好的接口的典范。当我们使用时，只需要传入一个必须的参数。但是，当默认的序列化或反序列机制不满足我们的要求时，我们又可以传入更多的参数来定制序列化或反序列化的规则，既做到了接口简单易用，又做到了充分的扩展性和灵活性。

2018.4.19
	进程和线程：
		现代操作系统比如Mac OS X，UNIX，Linux，Windows等，都是支持“多任务”的操作系统。
		什么叫“多任务”呢？简单地说，就是操作系统可以同时运行多个任务。
		多任务的实现方式有3种：
			多进程模式
			多线程模式
			多进程+多线程模式
		线程是最小的执行单元，而进程由至少一个线程组成。如何调度进程和线程，完全由操作系统决定，程序不能决定什么时候执行，执行多长时间
		多进程和多线程程序涉及到同步、数据共享的问题，编写起来更复杂
	多进程：
		fork：
			Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊；调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回；
			子进程永远返回0，父进程返回子进程的ID；一个父进程可以fork出很多子进程，一个父进程要记下每个子进程的 ID，而子进程只要调用getppid()就可以拿到父进程的ID；
			import os

			print('Process (%s) start...' % os.getpid())
			# Only works on Unix/Linux/Mac:
			pid = os.fork()
			if pid == 0:
			    print('I am child process (%s) and my parent is %s.' % (os.getpid(), os.getppid()))
			else:
			    print('I (%s) just created a child process (%s).' % (os.getpid(), pid))
			运行结果如下：

			Process (876) start...
			I (876) just created a child process (877).
			I am child process (877) and my parent is 876.
			有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。
			由于Windows没有fork调用，上面的代码在Windows上无法运行
		multiprocessing模块：
			该模块是跨平台版本的多进程模块。multiprocessing模块提供了一个Process类来代表一个进程对象。
			from multiprocessing import Process
			import os

				# 子进程要执行的代码
				def run_proc(name):
				    print('Run child process %s (%s)...' % (name, os.getpid()))

				if __name__=='__main__':
				    print('Parent process %s.' % os.getpid())
				    p = Process(target=run_proc, args=('test',))
				    print('Child process will start.')
				    p.start()
				    p.join()
				    print('Child process end.')
				执行结果如下：

				Parent process 928.
				Process will start.
				Run child process test (929)...
				Process end.
				创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单。

				join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。
		Pool:
			如果要启动大量的子进程，可以用进程池的方式批量创建子进程。
			对Pool对象调用join()方法会等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。
		子进程：
			子进程并不是自身，而是一个外部进程，我们创建子进程后，还要控制子进程的输入和输出
			subprocess模块可以让我们很方便的启动一个子进程，然后控制其输入输出
			如果子进程还要输入，则可以通过communicate（）方法输入
		进程间通信：
			python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。
			在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过pickle序列化再传到子进程去，所有，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。

	多线程：
			Python的标准库提供了两个模块：_thread和threading，_thread是低级模块，threading是高级模块，对_thread进行了封装。绝大多数情况下，我们只需要使用threading这个高级模块。
			启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行
		LOCK:
			多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了	
		多线程编程，模型复杂，容易发生冲突，必须用锁加以隔离，同时，又要小心死锁的发生。

		Python解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。多线程的并发在Python中就是一个美丽的梦。
	TreadLocal:
		ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源
		一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题。
	进程vs线程：
		线程切换：
		计算密集型 vs IO密集型：
			计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。
			IO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，完全无法提升运行效率。对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差。
		异步IO：
			用异步IO编程模型来实现多任务是一个主要的趋势
			对应到Python语言，单线程的异步编程模型称为协程，有了协程的支持，就可以基于事件驱动编写高效的多任务程序
	分布式进程：
		在Thread和Process中，应当优选Process，因为Process更稳定，而且，Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。
		Python的分布式进程接口简单，封装良好，适合需要把繁重任务分布到多台机器的环境下。

注意Queue的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小。比如发送一个处理日志文件的任务，就不要发送几百兆的日志文件本身，而是发送日志文件存放的完整路径，由Worker进程再去共享的磁盘上读取文件。
2018.4.21
	正则表达式：
			^表示行的开头，^\d表示必须以数字开头。

			$表示行的结束，\d$表示必须以数字结束
			re 模块：
				import re 
				re.match(r'^\d{3}\-\d{3,8}$','010-12345')
			切分字符串：
				>>> re.split(r'[\s\,\;]+', 'a,b;; c  d')
					['a', 'b', 'c', 'd']
			分组：
				除了简单地判断是否匹配之外，正则表达式还有提取子串的强大功能。用()表示的就是要提取的分组（Group）
				>>> m = re.match(r'^(\d{3})-(\d{3,8})$', '010-12345')
				>>> m
				<_sre.SRE_Match object; span=(0, 9), match='010-12345'>
				>>> m.group(0)
				'010-12345'
				>>> m.group(1)
				'010'
				>>> m.group(2)
				'12345'

				>>> t = '19:05:30'
				>>> m = re.match(r'^(0[0-9]|1[0-9]|2[0-3]|[0-9])\:(0[0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-9]|5[0-9]|[0-9])\:(0[0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-9]|5[0-9]|[0-9])$', t)
				>>> m.groups()
				('19', '05', '30')
			贪婪匹配：
				>>> re.match(r'^(\d+)(0*)$', '102300').groups()
				('102300', '')
				必须让\d+采用非贪婪匹配（也就是尽可能少匹配），才能把后面的0匹配出来，加个?就可以让\d+采用非贪婪匹配：

				>>> re.match(r'^(\d+?)(0*)$', '102300').groups()
				('1023', '00')
			编译：
				当我们在Python中使用正则表达式时，re模块内部会干两件事情：

				编译正则表达式，如果正则表达式的字符串本身不合法，会报错；

				用编译后的正则表达式去匹配字符串。
				>>> import re
				# 编译:
				>>> re_telephone = re.compile(r'^(\d{3})-(\d{3,8})$')
				# 使用：
				>>> re_telephone.match('010-12345').groups()
				('010', '12345')
				>>> re_telephone.match('010-8086').groups()
				('010', '8086')
2018.4.22
python 常见内建模块：
	datetime:
		获取当前日期：
			from datetime import datetime
			now = datetime.now()
			print(now)
		获取指定日期和时间：
			from datetime import datetime 
			dt = datetime(2018,4,22,19,12,20)#用指定日期时间创建datetime
			print(dt)#2018-04-22 19:12:20
		datetime 转换为timestamp:
			timestamp的值与时区没关系，全球各地计算机任意时刻timestamp完全一样，timestamp一确定，其UTC时间就确定了，转换到任意时区的时间就确定
			from datetime import datetime
			dt = datetime(2015,4,19,12,20)
			dt.timestamp()#把datetime转换为timestamp 1429417200.0
		timestamp转换为datetime:
			使用datetime提供的fromtimestamp()方法
			t = 1429417200.0
			t1 = datetime.fromtimestamp(t)#本地时间
			print(t1)#2015-04-19 12:20:00
			t2 = datetime.utcfromtimestamp(t)#UTC时间
			print(t2)#2015-04-19 04:20:00
		str 转换为datetime:
			使用datetime.strptime()实现
			from datetime import datetime
			cday = datetime.strptime('2015-6-1 18:19:59','%Y-%m-%d %H:%M:%S')
			print(cday)#2015-06-01 18:19:59
		datetime 转换为 str:
			使用strftime()实现
			now = datetime.now()
			print(now.strftime('%a,%b %d %H:%M'))#Mon, May 05 16:28
		datetime加减：
			加减可以直接用+和-运算符，不过需要导入timedelta这个类：
			from datetime import datetime, timedelta
			now = datetime.now()
			now#datetime.datetime(2015, 5, 18, 16, 57, 3, 540997)
			now + timedelta(hours=10)#datetime.datetime(2015, 5, 19, 2, 57, 3, 540997)
			now + timedelta(days=2, hours=12)#datetime.datetime(2015, 5, 21, 4, 57, 3, 540997)
		本地时间转换为UTF时间：
			本地时间是指系统设定时区的时间，例如北京时间是UTC+8:00时区的时间，而UTC时间指UTC+0:00时区的时间
			一个datetime类型有一个时区属性 tzinfo,但是默认为None，所以无法区分这个datetime到底是哪个时区，除非强行给datetime设置一个时区：
			from datetime import datetime ,timedelta,timezone
			tz_utc_8 = timezone(timedelta(hours=8))#创建时区UTC+8:00
			now = datetime.now()
			now#datetime.datetime(2015, 5, 18, 17, 2, 10, 871012)
			dt = now.replace(tzinfo=tz_utc_8)#强制设置为utc+8:00
			dt #datetime.datetime(2015, 5, 18, 17, 2, 10, 871012, tzinfo=datetime.timezone(datetime.timedelta(0, 28800)))
		时区转换：
			可以通过 utcnow()拿到当前时间，再转换为任意时区的时间
			utc_dt = datetime.utcnow().replace(tzinfo=timezone.utc)# 拿到UTC时间，并强制设置时区为UTC+0:00:
			print(utc_dt)#2015-05-18 09:05:12.377316+00:00
			bj_dt = utc_dt.astimezone(timezone(timedelta(hours=8)))#astimezone()将转换时区为北京时间
			print(bj_dt)2015-05-18 17:05:12.377316+08:00
		datime表示的时间需要时区信息才能确定一个特定的时间，否则只能视为本地时间
		如果要存储datetime，最佳的方法是将其转换为timestamp再存储，因为timestamp的值与时区完全无关
	collections:
		namedtuple:
			是一个函数，用来创建一个自定义的tuple对象，并且规定了tuple元素的个数，并且可以用属性而不是索引来引用tuple的某个元素
			from collections import namedtuple
			Point = namedtuple('Point',['x','y'])
			p = Point(1,2)
			p.x#1
			p.y#2
		deque:
			使用list来存储数据，是为了高效实现插入和删除操作的双向列表，适合用于队列和栈
			from collections import deque
			q = deque(['a','b','c'])
			q.append('x')
			q.appendleft('y')
			q#deque(['y','a','b','c','x'])
		defaultdict:
			使用dict时，引用的key不在的话，就会抛出keyerror,返回默认值，用defaultdict
			from collections import defaultdict
			dd = defaultdict(lambda: 'N/A')#默认值用函数返回，函数在常见defaultdict对象时传入
			dd['key']#'N/A'
		OrderedDict:
			使用dict时，key是无序的，在对dict做迭代时，无法确定key的顺序
			要保持key的顺序，可以用OrderedDict,key会按照插入的顺序排列，不是key本身排序
			from collections import OrderedDict
			od = OrderedDict()
			od['z'] = 1
			od['y'] = 2
			od['x'] = 3
			list(od.keys())#['z','y','x']
			OrderedDict可以实现一个fifo的dict，当容量超出限制时，先删除最早添加的key
		Counter:
			是一个简单的计数器，可以统计字符出现的个数,是dict的一个子类
			from collections import Counter
			c = Counter()
			for ch in 'programming':
				c[ch] = c[ch] + 1
			c#Counter({'g': 2, 'm': 2, 'r': 2, 'a': 1, 'i': 1, 'o': 1, 'n': 1, 'p': 1})
	base64:
		Base64是一种用64个字符来表示任意二进制数据的方法
		Base64是一种最常见的二进制编码方法
		Base64是一种任意二进制到文本字符串的编码方法，常用于在URL、cookie、网页传输少量二进制数据
	struct:
		用来解决bytes和其他二进制数据类型的转换
		struct的pack函数把任意数据类型变成bytes
		>>> import struct
		>>> struct.pack('>I', 10240099)
		b'\x00\x9c@c'
		>表示字节顺序是big-endian，也就是网络序，I表示4字节无符号整数。
	hashlib:
		摘要算法简介：
		python的hashlib提供了常见的摘要算法如MD5，SHA1等
		摘要算法：又称为哈希算法、散列算法，它通过一个函数（单向函数），把任意长度的数据转换为一个长度固定的数据串（通常用16进制的字符串表示）
		MD5：
			最常见的摘要算法，速度很快，生成结果是固定的128bit字节，通常用一个32位16进制字符串来表示
			import hashlib
			md5 = hashlib.md5()
			md5.update('how to use md5 in python hashlib?'.encode('utf-8'))
			print(md5.hexdigest())#d26a53750bc40b38b65a520292f69306
			也可以分快多次调用update（），计算结果一样
		SHA1：
			import hashlib

			sha1 = hashlib.sha1()
			sha1.update('how to use sha1 in '.encode('utf-8'))
			sha1.update('python hashlib?'.encode('utf-8'))
			print(sha1.hexdigest())
			结果是160bit字节，通常用40位的16进制字符串表示
		摘要算法应用：
			存储用户密码，不存储用户的明文口令，而是存储用户口令的摘要
			常用口令的MD5值很容易被计算出来，故需要原始口令加一个复杂字符串来实现，俗称“加盐”
			
			摘要算法在很多地方都有广泛的应用。要注意摘要算法不是加密算法，不能用于加密（因为无法通过摘要反推明文），只能用于防篡改，但是它的单向计算特性决定了可以在不存储明文口令的情况下验证用户口令。
2018.4.23
	hmac:
		和我们自定义的加salt算法不同，Hmac算法针对所有哈希算法都通用，无论是MD5还是SHA-1.采用Hmac替代我们自己的salt算法，可以使程序算法更标准化，也更安全。
		import hmac
		message = b'Hello,world!'
		key = b'secret'
		h = hmac.new(key,message,digestmod='MD5')
		h.hexdigest()#'fa4ee7d173f2d97ee79022d1a7355bcf'
		可见使用hmac和普通的hash算法非常类似。注意传入的key和message都是bytes类型，str类型需要先编码为bytes.
		python内置的hmac模块实现了标准的hmac算法，它利用一个key对message计算’杂凑‘后的哈hash,使用 hmac算法比标准hash算法更安全，因为针对相同的message，不同的key会产生不同的hash.
	itertools:
		itertools模块提供了非常有用的用于操作迭代对象的函数
		itertools提供的几个无限迭代器：
			count()会创建一个无限的迭代器
			cycle()会把传入的一个序列无限重复下去
			repeat()把一个元素无限重复下去，不过提供的第二个参数就可以限定重复次数
			无限序列只有在for迭代是才会无限的迭代下去，
			通过takewhile()等函数根据条件判断来截取一个有限的序列
			import itertools
			natuals = itertools.count(1)#itertools.count(1,2)创建奇数序列
			ns = itertools.takewhile(lambda x: x <= 10,natuals)
			list(ns)#[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
		itertools提供的几个迭代器操作函数更有用：
			chain()可以把一组迭代对象串联起来，形成一个更大的迭代器
			groupby()把迭代器中相邻的重复元素挑出来放在一起：
			for key ,group in itertools.groupby('AaABBbCCAaA',lambda c : c.upper()):
				print(key,list(group))
			A ['A', 'a', 'A']
			B ['B', 'B', 'a']
			C ['C', 'C']
			A ['A', 'a', 'A']
		itertools模块提供的全部是处理迭代功能的函数，它们的返回值不是list,而是Iterator,只有用for循环迭代的时候才真正计算。
	contextlib:
		关闭文件资源：
			try ... finally
			with 语句
		并不是只有open()函数返回的fp对象才能使用with语句，实际上，任何对象只要实现了上下文管理，就可以用于with语句
		实现上下文管理是通过__enter__和__exit__这两个方法实现的

		@contextmanager
			编写__enter__和__exit__仍然很繁琐，因此Python的标准库contextlib提供了更简单的写法
			很多时候，我们希望在某段代码执行前后自动执行特定代码，也可以用@contextmanager实现
			@contextmanager让我们通过编写generator来简化上下文管理
		@closing
			如果一个对象没有实现上下文，我们就不能把它用于with语句。这个时候，可以用closing()来把该对象变为上下文对象
			closing也是一个经过@contextmanager装饰的generator
			它的作用就是把任意对象变为上下文对象，并支持with语句。

			@contextlib还有一些其他decorator，便于我们编写更简洁的代码
	urllib:
		urllib提供了一系列操作URL的功能
		Get:
			urllib的request模块可以非常方便的抓取URL的内容，也就是发送一个get请求到指定的页面，然后返回HTTP的响应
			如果我们要想模拟浏览器发送GET请求，就需要使用Request对象，通过往Request对象添加HTTP头，我们就可以把请求伪装成浏览器。
		Post:
			如果要以POST发送一个请求，只需要把参数data以bytes形式传入
		Handler:
			如果还需要更复杂的控制，比如通过一个proxy去访问网站，我们需要利用proxyhandler来处理
		urllib提供的功能就是利用程序去执行各种HTTP请求。如果要模拟浏览器完成特定功能，需要把请求伪装成浏览器。伪装的方法是先监控浏览器发出的请求，在根据浏览器的请求头来伪装，user-agent头就是用来标识浏览器的。
	XML:
		操作XML有两种方法：DOM和SAX。DOM会把整个XML读入内存，解析为树，因此占用内存大，解析慢，优点是可以任意遍历树的节点。SAX是流模式，边读边解析，占用内存小，解析快，缺点是我们需要自己处理事件。

		正常情况下，优先考虑SAX，因为DOM实在太占内存。
		在Python中使用SAX解析XML非常简洁，通常我们关心的事件是start_element，end_element和char_data，准备好这3个函数，然后就可以解析xml了
		解析XML时，注意找出自己感兴趣的节点，响应事件时，把节点数据保存起来。解析完毕后，就可以处理数据。
	HTMLParser:
		HTML本质上是XML的子集，但是HTML的语法没有XML那么严格，所以不能用标准的DOM或SAX来解析HTML。

		好在Python提供了HTMLParser来非常方便地解析HTML，只需简单几行代码：
		利用HTMLParser，可以把网页中的文本、图像等解析出来。
常用第三方模块：
	pillow：python图像处理标准库
		sudo pip install pillow
		PIL提供了操作图像的强大功能，可以通过简单的代码完成复杂的图像处理
		from PIL import Image
		操作图像：
			缩放、切片、旋转、滤镜、输出文字、调色板、模糊
	requests:
		我们已经讲解了Python内置的urllib模块，用于访问网络资源。但是，它用起来比较麻烦，而且，缺少很多实用的高级功能。

		更好的方案是使用requests。它是一个Python第三方库，处理URL资源特别方便。
	chardet:
		用它来检测编码，简单易用。chardet支持检测中文、日文、韩文等多种语言。
		>>> data = '离离原上草，一岁一枯荣'.encode('gbk')
		>>> chardet.detect(data)
		{'encoding': 'GB2312', 'confidence': 0.7407407407407407, 'language': 'Chinese'}
		用chardet检测编码，使用简单。获取到编码后，再转换为str，就可以方便后续处理
	psutil:
		在Python中获取系统信息的另一个好办法是使用psutil这个第三方模块。顾名思义，psutil = process and system utilities，它不仅可以通过一两行代码实现系统监控，还可以跨平台使用，支持Linux／UNIX／OSX／Windows等，是系统管理员和运维小伙伴不可或缺的必备模块。
		获取cpu信息
		获取内存信息
		获取磁盘信息
		获取网络信息#获取网络连接信息需要root权限，这种情况下，可以退出Python交互环境，用sudo重新启动sudo python3
		获取进程信息#和获取网络连接类似，获取一个root用户的进程需要root权限，启动Python交互环境或者.py文件时，需要sudo权限。
		psutil还提供了一个test()函数，可以模拟出ps命令的效果：
		psutil使得Python程序获取系统信息变得易如反掌。

		psutil还可以获取用户信息、Windows服务等很多有用的系统信息
virtualenv:
	virtualenv是如何创建“独立”的Python运行环境的呢？原理很简单，就是把系统Python复制一份到virtualenv的环境，用命令source venv/bin/activate进入一个virtualenv环境时，virtualenv会修改相关环境变量，让命令python和pip均指向当前的virtualenv环境。
	virtualenv为应用提供了隔离的Python运行环境，解决了不同应用间多版本的冲突问题。
图形界面：
	Python支持多种图形界面的第三方库，包括：
		TK、wxWidgets、Qt、GTK
		但是Python自带的库是支持Tk的Tkinter，使用Tkinter，无需安装任何包，就可以直接使用。本章简单介绍如何使用Tkinter进行GUI编程。
	Python内置的Tkinter可以满足基本的GUI程序的要求，如果是非常复杂的GUI程序，建议用操作系统原生支持的语言和库来编写。
2018.4.24
网络编程：
	tcp/ip简介：
		ip地址对应的实际上是计算机的网络接口，通常是网卡。
		ip协议负责把数据从一台计算机通过网络发送到另一台计算机。
		IP包的特点是按块发送，途径多个路由，但不保证能到达，也不保证顺序到达。
		IP地址实际上是一个32位整数称为IPv4
		IPv6地址实际上是一个128位整数
		tcp协议是建立在IP协议上的，tcp协议负责在两台计算机之间建立可靠连接，保证数据包按顺序到达。
		tcp协议会通过握手建立连接，然后对每个IP包编号，确保对方按顺序收到，如果包丢掉了，就自动重发
		许多高级协议如HTTP、SMTP都建立在tcp协议基础上
		一个tcp报文除了包含要传输的数据外，还包含源IP地址和目标IP地址，源端口和目标端口
	tcp编程：
		Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。
		大多数连接都是可靠的TCP连接。创建TCP连接时，主动发起连接的叫客户端，被动响应连接的叫服务器。

		用TCP协议进行Socket编程在Python中十分简单，对于客户端，要主动连接服务器的IP和指定端口，对于服务器，要首先监听指定端口，然后，对每一个新的连接，创建一个线程或进程来处理。通常，服务器程序会无限运行下去。

		同一个端口，被一个Socket绑定了以后，就不能被别的Socket绑定了。
		需要注意的是，客户端程序运行完毕就退出了，而服务器程序会永远运行下去，必须按Ctrl+C退出程序
	udp编程：
		TCP是建立可靠连接，并且通信双方都可以以流的形式发送数据。相对TCP，UDP则是面向无连接的协议。
		使用UDP协议时，不需要建立连接，只需要知道对方的IP地址和端口号，就可以直接发数据包。但是，能不能到达就不知道了。

		虽然用UDP传输数据不可靠，但它的优点是和TCP比，速度快，对于不要求可靠到达的数据，就可以使用UDP协议。
		UDP的使用与TCP类似，但是不需要建立连接。此外，服务器绑定UDP端口和TCP端口互不冲突，也就是说，UDP的9999端口与TCP的9999端口可以各自绑定。

电子邮件：
	一封电子邮件的旅程就是：

	发件人 -> MUA -> MTA -> MTA -> 若干个MTA -> MDA <- MUA <- 收件人
	MUA:message user agent  邮件用户代理
	MTA:mail transfer agent  邮件传输代理
	MDA:mail delivery agent  邮件投递代理
	有了上述基本概念，要编写程序来发送和接收邮件，本质上就是：
	编写MUA把邮件发到MTA；
	编写MUA从MDA上收邮件。
	发邮件时，MUA和MTA使用的协议就是SMTP：Simple Mail Transfer Protocol，后面的MTA到另一个MTA也是用SMTP协议。
	收邮件时，MUA和MDA使用的协议有两种：POP：Post Office Protocol，目前版本是3，俗称POP3；IMAP：Internet Message Access Protocol，目前版本是4，优点是不但能取邮件，还可以直接操作MDA上存储的邮件，比如从收件箱移到垃圾箱，等等。
2018.4.26
	SMTP发送邮件：
		使用Python的smtplib发送邮件十分简单，只要掌握了各种邮件类型的构造方法，正确设置好邮件头，就可以顺利发出。

		构造一个邮件对象就是一个Messag对象，如果构造一个MIMEText对象，就表示一个文本邮件对象，如果构造一个MIMEImage对象，就表示一个作为附件的图片，要把多个对象组合起来，就用MIMEMultipart对象，而MIMEBase可以表示任何对象。它们的继承关系如下：

		Message
		+- MIMEBase
		   +- MIMEMultipart
		   +- MIMENonMultipart
		      +- MIMEMessage
		      +- MIMEText
		      +- MIMEImage
		这种嵌套关系就可以构造出任意复杂的邮件。
	pop3收取邮件：
		收取邮件分为两步：
			用poplib把邮件的原始文本下载到本地；poplib实现了pop3协议，可以用来收邮件
			用email解析原始文本，还原为邮件对象
		用Python的poplib模块收取邮件分两步：第一步是用POP3协议把邮件获取到本地，第二步是用email模块把原始邮件解析为Message对象，然后，用适当的形式把邮件内容展示给用户即可。

访问数据库：
	为了便于保存和读取数据，而且，能直接通过条件快速查询到指定的数据，就出现了数据库database，这种专门用于集中存储和查询的软件
	在关系数据库中，这种基于表（table）的一对多的关系就是关系数据库的基础
	表示数据库中存放关系数据的集合，，表和表之间通过外键关联

	SQLite:
		是一种嵌入式数据库，它的数据库就是一个文件。sqlite本身是c写的，而且体积小，所以常被集成到各种应用程序中，甚至在iOS和Android的app中都可以集成
		python内置了sqlite3
			要操作关系数据库，首先要连接到数据库，一个数据库连接称为connection
			连接到数据库后，需要打开游标，称之为cursor，通过cursor执行sql语句，然后执行结果
			python定义了一套操作数据库的api接口，任何数据要连接到Python，只需要提供符合python标准的数据库驱动即可。

			在Python中操作数据库时，要先导入数据库对应的驱动，然后，通过Connection对象和Cursor对象操作数据。

			要确保打开的Connection对象和Cursor对象都正确地被关闭，否则，资源就会泄露。

			如何才能确保出错的情况下也关闭掉Connection对象和Cursor对象呢？请回忆try:...except:...finally:...的用法。
	使用MySQL：
		MySQL是Web世界中使用最广泛的数据库服务器。SQLite的特点是轻量级、可嵌入，但不能承受高并发访问，适合桌面和移动应用。而MySQL是为服务器端设计的数据库，能承受高并发访问，同时占用的内存也远远大于SQLite。
		MySQL内部有多种数据库引擎，最常用的引擎是支持数据库事务的InnoDB
		由于Python的DB-API定义都是通用的，所以，操作MySQL的数据库代码和SQLite类似。
		执行INSERT等操作后要调用commit()提交事务；

		MySQL的SQL占位符是%s。
	使用SQLAlchemy:
		数据库表是一个二维表，包含多行多列。把一个表的内容用Python的数据结构表示出来的话，可以用一个list表示多行，list的每一个元素是tuple，表示一行记录，比如，包含id和name的user表：
		但是用tuple表示一行很难看出表的结构。如果把一个tuple用class实例来表示，就可以更容易地看出表的结构来：
			于是出现 ORM技术：Object-Relational Mapping,把关系数据库的表结构映射到对象上。
			但是由谁来做这个转换呢？所以ORM框架应运而生。

			在Python中，最有名的ORM框架是SQLAlchemy
			ORM框架的作用就是把数据库表的一行记录与一个对象互相做自动转换。

			正确使用ORM的前提是了解关系数据库的原理。
web开发：
	Web开发也经历了好几个阶段：

		1.静态Web页面：由文本编辑器直接编辑并生成静态的HTML页面，如果要修改Web页面的内容，就需要再次编辑HTML源文件，早期的互联网Web页面就是静态的；

		2.CGI：由于静态Web页面无法与用户交互，比如用户填写了一个注册表单，静态Web页面就无法处理。要处理用户发送的动态数据，出现了Common Gateway Interface，简称CGI，用C/C++编写。

		3.ASP/JSP/PHP：由于Web应用特点是修改频繁，用C/C++这样的低级语言非常不适合Web开发，而脚本语言由于开发效率高，与HTML结合紧密，因此，迅速取代了CGI模式。ASP是微软推出的用VBScript脚本编程的Web开发技术，而JSP用Java来编写脚本，PHP本身则是开源的脚本语言。

		4.MVC：为了解决直接用脚本语言嵌入HTML导致的可维护性差的问题，Web应用也引入了Model-View-Controller的模式，来简化Web开发。ASP发展为ASP.Net，JSP和PHP也有一大堆MVC框架。

		目前，Web开发技术仍在快速发展中，异步开发、新的MVVM前端技术层出不穷。
	http协议简介：
			HTTP请求
			跟踪了新浪的首页，我们来总结一下HTTP请求的流程：
			步骤1：浏览器首先向服务器发送HTTP请求，请求包括：
			方法：GET还是POST，GET仅请求资源，POST会附带用户数据；
			路径：/full/url/path；
			域名：由Host头指定：Host: www.sina.com.cn
			以及其他相关的Header；
			如果是POST，那么请求还包括一个Body，包含用户数据。

			步骤2：服务器向浏览器返回HTTP响应，响应包括：
			响应代码：200表示成功，3xx表示重定向，4xx表示客户端发送的请求有错误，5xx表示服务器端处理时发生了错误；
			响应类型：由Content-Type指定；
			以及其他相关的Header；
			通常服务器的HTTP响应会携带内容，也就是有一个Body，包含响应的内容，网页的HTML源码就在Body中。

			步骤3：如果浏览器还需要继续向服务器请求其他资源，比如图片，就再次发出HTTP请求，重复步骤1、2。
			Web采用的HTTP协议采用了非常简单的请求-响应模式，从而大大简化了开发。当我们编写一个页面时，我们只需要在HTTP请求中把HTML发送出去，不需要考虑如何附带图片、视频等，浏览器如果需要请求图片和视频，它会发送另一个HTTP请求，因此，一个HTTP请求只处理一个资源。
			HTTP协议同时具备极强的扩展性，虽然浏览器请求的是http://www.sina.com.cn/的首页，但是新浪在HTML中可以链入其他服务器的资源，比如<img src="http://i1.sinaimg.cn/home/2013/1008/U8455P30DT20131008135420.png">，从而将请求压力分散到各个服务器上，并且，一个站点可以链接到其他站点，无数个站点互相链接起来，就形成了World Wide Web，简称WWW。

			HTTP格式
			每个HTTP请求和响应都遵循相同的格式，一个HTTP包含Header和Body两部分，其中Body是可选的。
			HTTP协议是一种文本协议，所以，它的格式也非常简单。

			HTTP GET请求的格式：
			GET /path HTTP/1.1
			Header1: Value1
			Header2: Value2
			Header3: Value3
			每个Header一行一个，换行符是\r\n。

			HTTP POST请求的格式：
			POST /path HTTP/1.1
			Header1: Value1
			Header2: Value2
			Header3: Value3

			body data goes here...
			当遇到连续两个\r\n时，Header部分结束，后面的数据全部是Body。

			HTTP响应的格式：
			200 OK
			Header1: Value1
			Header2: Value2
			Header3: Value3

			body data goes here...
			HTTP响应如果包含body，也是通过\r\n\r\n来分隔的。请再次注意，Body的数据类型由Content-Type头来确定，如果是网页，Body就是文本，如果是图片，Body就是图片的二进制数据。

			当存在Content-Encoding时，Body数据是被压缩的，最常见的压缩方式是gzip，所以，看到Content-Encoding: gzip时，需要将Body数据先解压缩，才能得到真正的数据。压缩的目的在于减少Body的大小，加快网络传输。

	html简介：
		如果要学习Web开发，首先要对HTML、CSS和JavaScript作一定的了解。HTML定义了页面的内容，CSS来控制页面元素的样式，而JavaScript负责页面的交互逻辑。

	WSGI接口：Web Server Gateway Interface，一个统一的接口，让我们专心用Python编写Web业务
		一个Web应用的本质就是：

			浏览器发送一个HTTP请求；
			服务器收到请求，生成一个HTML文档；
			服务器把HTML文档作为HTTP响应的Body发送给浏览器；
			浏览器收到HTTP响应，从HTTP Body取出HTML文档并显示。
			所以，最简单的Web应用就是先把HTML用文件保存好，用一个现成的HTTP服务器软件，接收用户请求，从文件中读取HTML，返回。Apache、Nginx、Lighttpd等这些常见的静态服务器就是干这件事情的。
		无论多么复杂的Web应用程序，入口都是一个WSGI处理函数。HTTP请求的所有输入信息都可以通过environ获得，HTTP响应的输出都可以通过start_response()加上函数返回值作为Body。

		复杂的Web应用程序，光靠一个WSGI函数来处理还是太底层了，我们需要在WSGI之上再抽象出Web框架，进一步简化Web开发。
	使用web框架：
		如何处理HTTP请求不是问题，问题是如何处理100个不同的URL
		每一个URL可以对应get和post请求（）常用，还有put和delete请求

		同一个URL、signin分别有get和post两种请求，映射到两个处理函数中。
		flask通过Python的装饰器在内部自动地把URL和函数给关联起来了
		除了Flask，常见的Python Web框架还有：

			Django：全能型Web框架；

			web.py：一个小巧的Web框架；

			Bottle：和Flask类似的Web框架；

			Tornado：Facebook的开源异步Web框架。
		有了Web框架，我们在编写Web应用时，注意力就从WSGI处理函数转移到URL+对应的处理函数，这样，编写Web App就更加简单了。

		在编写URL处理函数时，除了配置URL外，从HTTP请求拿到用户数据也是非常重要的。Web框架都提供了自己的API来实现这些功能。Flask通过request.form['name']来获取表单的内容。

	使用模板：
		通过MVC，我们在Python代码中处理M：Model和C：Controller，而V：View是通过模板处理的，这样，我们就成功地把Python代码和HTML代码最大限度地分离了。
		使用模板的另一大好处是，模板改起来很方便，而且，改完保存后，刷新浏览器就能看到最新的效果，这对于调试HTML、CSS和JavaScript的前端工程师来说实在是太重要了。
		在Jinja2模板中，我们用{{ name }}表示一个需要替换的变量。很多时候，还需要循环、条件判断等指令语句，在Jinja2中，用{% ... %}表示指令。
		除了Jinja2，常见的模板还有：

		Mako：用<% ... %>和${xxx}的一个模板；

		Cheetah：也是用<% ... %>和${xxx}的一个模板；

		Django：Django是一站式框架，内置一个用{% ... %}和{{ xxx }}的模板。
		有了MVC，我们就分离了Python代码和HTML代码。HTML代码全部放到模板里，写起来更有效率。
异步IO:
	由于我们要解决的问题是CPU高速执行能力和IO设备的龟速严重不匹配，多线程和多进程只是解决这一问题的一种方法。
	另一种解决IO问题的方法是异步IO。当代码需要执行一个耗时的IO操作时，它只发出IO指令，并不等待IO结果，然后就去执行其他代码了。一段时间后，当IO返回结果时，再通知CPU进行处理。
	
	同步IO模型的代码是无法实现异步IO模型的。
	异步IO模型需要一个消息循环，在消息循环中，主线程不断地重复“读取消息-处理消息”这一过程：

	协程：
		又称微线程，纤程。coroutine
		但协程的特点在于是一个线程执行，那和多线程比，协程有何优势？
		最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。
		第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。
		因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。












